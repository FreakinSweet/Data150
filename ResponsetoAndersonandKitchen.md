# Response to Anderson and Kitchen

I disagree with Anderson - I believe that even in the face of having an infinite data set and almost annihilating the statistical error that was such an issue in the old ways of surveying a limited amount of individuals, we cannot say that causation is done away with in the face of very very strong correlation. I think this, because our interpretation of the data is still what matters at the end. Sure, we may have boundless cellular data to describe the location of all people at any given time, but it is the interpretation and conclusions we make from that data that matter... it doesn't remove the possibility, I believe, of our failure to interpret the data correctly. I think it just reorders the steps of older statistics... previously, like it was stated in Anderson's paper, we first came up with a hypothesis, then created data through observation and experimentation, and then concluded whether our hypothesis was true or false. Now, I think it has only been re-ordered: First, we have data created through observation only, and then we use machine learning algorithms to analyze patterns in the data. This is the step I am most suspicious of, though I admit I don't know how they work, and so I can't speak so much to it. Then, after the analysis of all patterns in the data, we hypothesize, and this is the problem, it is only analysis, there is no conclusion.
