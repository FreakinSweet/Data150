# Blurbenstocken

### Q1: "Describe the promise, pitfalls and ways forward Blumenstock uses as the foundation for his thesis."

##### A1: Mostly Blumenstock, though I use a few examples of my own:
The most immediately obvious potential that big data has is the potential to collect data that could not be before - for example, third world countries. Before satellites and cellphones, surveys would have to be conducted, much money and time expended in the process. Now, these new technologies which allow data scientists to idly and remotely collect massive amounts of information, these allow for new discoveries to be made in third world countries, allowing those in the first-world to best understand how to aid those in need. This is only one application.
  
Unfortunately, this technology is so new, that the long-term effects of its usage haven't been explored yet, and the readiness with which it has been implemented, and has replaced older trusted stastical surveys and methods is concerning. The pitfall of big data is that we don't know its pitfalls as well as traditional statistics. One problem that has surfaced on platforms like YouTube and Facebook is biased algorithms - what if the machine learning algorithm which is necessary to interpret the seemingly infinite quantities of data goes awry? It has in our social media platfors, and likewise, may in the other applications of big data statistics. 
  
To ensure that as few incorrect conclusions are come to as a result of the new big data movement, it should be phased in instead of instantly replacing traditional statistics. We know how to use traditional statistics to get the informmation we desire, and we know its limitations quite well. We don't know this yet of big data, so replacing old statistics so swiftly comes with unknown risk. Further improvements in the trustworthiness of big data would be had if there was more collaboration in the private sector. Sharing data pools for the most diverse datasets possible will help big data. 

### Q2: "How do you respond to these ideas regarding “good intent”, “transparency” and the difficult “balancing act” when considering the intersection of human development with data science?"

“Good intent is not enough in data science when dealing with the problems which determine people’s experiences” Anna Raymond

“Transparency is the underlying issue to many of these problems, so an increase in this on both ends (data based issues & human based issues) could lead to better results” Nira Nair

“In lieu of such drastic potential for promoting applications yet demoralizing hinderances, the balancing act can become difficult.” Kayla Seggelke

##### A1: 
In response to Anna - I couldn't agree more. This makes me think of Facebook, Youtube, Twitter. When they say that their algorithms are biased, and proceed to modify them, this raises a problem of trust: Was the original algorithm just fine and well, and are then then manipulating it to their advantage or for some sick puropose? Or is it true what they say?

In response to Nira - 

In response to Kayla - 





